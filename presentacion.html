<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Aplicaciones de los embeddings satelitales de Google AlphaEarth Foundations en el análisis geoespacial: clasificación de uso del suelo, modelado de distribución de especies y diseño de muestreo</title>
    <meta charset="utf-8" />
    <meta name="author" content="José Ramón Martínez Batlle" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Aplicaciones de los embeddings satelitales de Google AlphaEarth Foundations en el análisis geoespacial: clasificación de uso del suelo, modelado de distribución de especies y diseño de muestreo
]
.author[
### José Ramón Martínez Batlle
]
.institute[
### Universidad Autónoma de Santo Domingo (UASD)
]
.date[
### Actualizado: 2025-11-19
]

---

class: large



&lt;style type="text/css"&gt;
.title-slide {
  &lt;!-- background-image: url('fondo.jpg'); --&gt;
  background-size: cover;
  background-position: center;
}

.title-slide .remark-slide-content {
  background: rgba(0, 0, 0, 0.7);
  color: white;
}

.large { font-size: 150% }
.medium { font-size: 130% }
.small { font-size: 110% }
.tiny { font-size: 80% }

.green { color: #2E8B57; }
.blue { color: #4169E1; }
.red { color: #DC143C; }

.highlight {
  background-color: #ffff99;
  padding: 2px 4px;
}

.box {
  background-color: #f0f8ff;
  border: 2px solid #4169E1;
  border-radius: 10px;
  padding: 20px;
  margin: 10px 0;
}

.equation {
  background-color: #f5f5f5;
  border-left: 5px solid #2E8B57;
  padding: 15px;
  margin: 10px 0;
  font-family: 'Courier New', monospace;
}

/* Ocultar número de diapositiva */
.remark-slide-number {
  display: none;
}

/* Diapositiva dedicada a una figura (sin márgenes internos) */
.remark-slide-content.figure-slide {
  padding: 0;
}

/* Quitar margen del párrafo que envuelve la imagen */
.remark-slide-content.figure-slide p {
  margin: 0;
}

/* Imagen centrada */
.remark-slide-content.figure-slide img {
  display: block;
  margin: 0 auto;
}
&lt;/style&gt;

# ¿Qué son los embeddings de Google AlphaEarth Foundations (AEF)?

- Los embeddings de **Google AlphaEarth Foundations (AEF)** condensan información espacio–temporal derivada de series multiespectrales completas (p.ej., Sentinel, Landsat, mapas de cobertura, LiDAR, bioclima).

- Cada píxel es representado por un **vector numérico de alta dimensión** que captura características espectrales, temporales y espaciales.

- Su principal fortaleza es que **permiten realizar tareas de clasificación con muy pocos datos de entrenamiento**, evitando el entrenamiento de modelos de deep learning desde cero.

---
class: figure-slide, center, inverse, middle

&lt;img src="preprint-capture.jpg" width="57%" /&gt;

---
class: figure-slide, center, inverse, middle

&lt;img src="preprint-capture-hl.jpg" width="57%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="aef-animation.gif" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="paradigma-embedding-fields.jpg" width="65%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="ejemplo_embeddings.jpg" width="88%" /&gt;

---
class: large

# Objetivos

- Objetivo general: evaluar la utilidad práctica de los **embeddings de AlphaEarth Foundations** para apoyar diferentes procesos de análisis espacial en contextos ecológicos y territoriales de la República Dominicana. 

- Objetivos específicos:
  - Probar su desempeño en la modelación de la **distribución espacial de especies** empleando registros de presencia y técnicas de aprendizaje supervisado.
  - Evaluar la capacidad para **discriminar coberturas** en zonas agrícolas, forestales y urbanas.
  - Analizar su aplicación en el **diseño de muestreo estratificado**, utilizando la similitud entre embeddings para optimizar la representatividad espacial y ambiental

---
class: large, center, middle, inverse

# Objetivo 1

Probar desempeño de embeddings de AEF en la modelación de la **distribución espacial de especies** empleando registros de presencia y técnicas de aprendizaje supervisado.

Colaboración para mis estudiantes del semestre 2023-02, asignatura biogeografía: Adrián Montás, Ángel González, Arisleydi De la Cruz, Bryan Ramos, Claribel Ramírez, Manuel Reyes, Ramona Muñoz, Saderis Carmona, Yenny Santana

---
class: figure-slide, inverse, middle

&lt;img src="informes_hormigas_uasd_00.jpg" width="85%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="informes_hormigas_uasd_01.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="informes_hormigas_uasd_02.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="informes_hormigas_uasd_03.jpg" width="90%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="informes_hormigas_uasd_04.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="embeddings_uasd.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="registros_pa_brachymyrmex_uasd.jpg" width="95%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="probabilidad_brachymyrmex_uasd.jpg" width="80%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="probabilidad_0p5_umbral_brachymyrmex_uasd.jpg" width="80%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="auc_brachymyrmex_uasd.jpg" width="60%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="boyce_brahymyrmex_uasd.jpg" width="60%" /&gt;

---
class: large

# Conclusiones del Objetivo 1

- **Los embeddings AEF reflejan gradientes ambientales finos** dentro del campus, capturando variación espacial relevante.
- **La extracción de valores ambientales por hexágono H3 fue exitosa**, generando una base homogénea para integrar las presencias.
- **Los modelos exploratorios muestran potencial predictivo** de los embeddings como variables para la distribución

---
class: large, center, middle, inverse

# Objetivo 2

Evaluar la capacidad de los embeddings satelitales de Google AEF para discriminar coberturas agrícolas, forestales y urbanas

Colaboración para Kénnida Polanco.

---
class: large

# Contexto

Para este objetivo se seleccionó un área con presencia simultánea de:

- **Agroecosistemas**
- **Bosque seco / matorral** (clases forestales/arbustivas)
- **Humedales** (varias)
- **Áreas urbanizadas**

---
class: large

# Flujo metodológico general

A continuación se muestra el resumen metodológico seguido para este objetivo, basado en tres componentes:

1. **Obtención de las máscaras de entrenamiento** mediante SAM (Segment Anything) usando el cuaderno adaptado de *Qiusheng Wu*, paquetes `samgeo`, `geemap`, en Google Colab.
2. **Curación y unificación de clases** en QGIS.
3. **Clasificación supervisada con embeddings AEF** mediante Random Forest y validación cruzada *k-folds* en Google Earth Engine.


---
class: large, center, middle, inverse

# Metodología

---
class: figure-slide, inverse, middle



![](graphical-methodology.jpg)

---
class: figure-slide, center, inverse, middle

&lt;img src="capturas_4.jpg" width="50%" /&gt;

---
class: large

## 1. Obtención de imágenes de alta resolución (ESRI World Imagery)

Se descargó una imagen de referencia del área seleccionada empleando *ESRI World Imagery* con resolución aproximada de **5–10 m**, de manera que fuera coherente con la escala representada en los embeddings AEF.

---
class: large

## 2. Segmentación automática con Segment Anything (SAM)

La segmentación se realizó usando cuaderno Jupyter. El procesamiento incluyó:

* Uso del modelo **ViT-H** (SAM), adecuado para imágenes de alta resolución pero útil también para imágenes de mediana resolución. Eficiente por su relación sensibilidad–costo computacional.
* Aplicación de `sam.generate()` con `unique=True` para obtener **instancias diferenciadas**.
* Ajuste de hiperparámetros (`points_per_side`, `pred_iou_thresh`, `crop_n_layers`, etc.) para aumentar la densidad de máscaras.

---
class: figure-slide, inverse, middle

&lt;img src="samgeo-vit-h-generate-mask-kwargs.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="salida-seriada.gif" width="100%" /&gt;

---

## 3. Limpieza y edición mínima en QGIS

Las máscaras obtenidas se exportaron a GeoPackage, donde se realizó una edición mínima:

* Corrección de pequeñas islas y polígonos erróneos.
* Eliminación de duplicados.
* Fusión de parches contiguos cuando correspondían a una misma cobertura.

Se añadieron dos campos:

* `class_id` (entero 1–8)
* `class_label` (nombre de la clase)

---
class: figure-slide, inverse, middle

&lt;img src="mascaras_entrenamiento_qgis_color.jpg" width="100%" /&gt;

---
class: large

## 4. Clasificación supervisada con embeddings AEF en Google Earth Engine

### Pasos principales

* Se definió un **AOI** a partir del *buffer de 1 km* del socioecosistema.
* Se extrajeron los embeddings mediante:


``` python
emb_image = ee.Image("GOOGLE/AE/IMG_V1").clip(aoi)
```

* Se muestrearon los píxeles según los polígonos curados:


``` python
sample = emb_image.sampleRegions(
    collection=fc,
    properties=["class_id"],
    scale=40,   # ajustado para evitar EEException: memory exceeded
    geometries=False
)
```

---
class: large

* Se añadieron **5 folds** para validación cruzada:


``` python
sample = sample.randomColumn("rand").divide(k).int()
```

* Se entrenó un clasificador:


``` python
classifier = ee.Classifier.smileRandomForest(
    numberOfTrees=100,
    minLeafPopulation=5
)
```

---
class: large

## 5. Resultados de la validación cruzada (5-fold CV)

Los resultados fueron evaluados en términos de:

* **Kappa de Cohen**
* **Exactitud global (OA)**
* **Matriz de confusión por pliegue**

---
class: figure-slide, inverse, middle

&lt;img src="metricas-k-fold-cv.jpg" width="97%" /&gt;

---
class: large, center, middle, inverse

# Mapa de clasificación

---
class: figure-slide, inverse, middle

&lt;img src="mapa_clasificacion.jpg" width="100%" /&gt;

---
class: large

# Conclusiones del Objetivo 2

* Los embeddings de AEF **sí capturan diferencias estructurales** entre agroecosistemas, áreas forestales/arbustivas y zonas urbanas.
* Con solo unos pocos polígonos de entrenamiento (segmentados vía SAM), se logró una clasificación robusta.
* El uso combinado de **SAM + QGIS + AEF embeddings + Random Forest** constituye un flujo de trabajo reproducible y eficiente para análisis de cobertura sin necesidad de deep learning complejo.
* La validación cruzada mostró niveles consistentes de desempeño entre pliegues, indicando estabilidad del clasificador.

---
class: large, center, middle, inverse

# Objetivo 3

Analizar la aplicación de embeddings de AEF en el **diseño de muestreo estratificado**, utilizando la similitud entre embeddings para optimizar la representatividad espacial y ambiental

Colaboración para María Fernanda Rodríguez y Wellin Brito.

---
class: figure-slide, inverse, middle




&lt;img src="graphical-methodology-don-gregorio.jpg" width="95%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-lejos-0-google.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-lejos-1-embeddings-2022.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-lejos-2-embeddings-2023.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-lejos-3-similaridad-2022-2023.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-lejos-0-google.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-cerca-0-google-puntos-jicoteas.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-cerca-1-drone.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-cerca-2-embeddings-puntos-jicoteas.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="calculos-rstudio.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-cerca-3-clasificacion-similaridad-puntos-jicoteas.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="serie-cerca-4-puntos-candidatos.jpg" width="100%" /&gt;

---
class: figure-slide, inverse, middle

&lt;img src="puntos-muestreo-solenodon.gif" width="100%" /&gt;

---
class: large

# Conclusiones del Objetivo 3

- **Los embeddings AEF permiten definir estratos ambientales** sin mapas previos, usando solo similitud por coseno.

- **El umbral aprendido localmente genera estratos estables**, coherentes con los hábitats asociados a los puntos de terreno.

- **El muestreo estratificado resultante es más representativo**, asignando puntos según la estructura ambiental real del área.

---
class: large, inverse, center, middle

# Gracias por su atención

&lt;section style="font-size: 36px; text-align: center;"&gt;

&lt;br&gt;

&lt;img src="email-icon.png" style="display: inline-block; vertical-align: middle;" width="48"/&gt; jmartinez19@uasd.edu.do

&lt;br&gt;

&lt;img src="gh-icon.png" style="display: inline-block; vertical-align: middle;" width="48"/&gt; geofis

&lt;/section&gt;

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
